<!DOCTYPE html>
<html lang="en-US" >
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<meta http-equiv="Content-Type" content="UTF-8" />
<title>Using the Kafka Handler</title>
<meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)" />
<meta name="description" content="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic." />
<meta name="dcterms.created" content="2018-09-04T10:47:42Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Fusion Middleware Using Oracle GoldenGate for Big Data" />
<meta name="dcterms.identifier" content="E89845-03" />
<meta name="dcterms.isVersionOf" content="GADBD" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2015, 2018, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="http://docs.oracle.com/goldengate/bd123210/gg-bd/index.html" title="Home" type="text/html" />
<link rel="Copyright" href="../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../nav/js/doccd.js" charset="UTF-8"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Prev" href="using-jdbc-handler.htm" title="Previous" type="text/html" />
<link rel="Next" href="using-kafka-connect-handler.htm" title="Next" type="text/html" />
<link rel="alternate" href="GADBD.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/fonts.css">
<link rel="stylesheet" href="../dcommon/css/foundation.css">
<link rel="stylesheet" href="../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../nav/css/html5.css">
<link rel="stylesheet" href="../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
<script>window.ohcglobal || document.write('<script src="/en/dcommon/js/global.js">\x3C/script>')</script></head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<a id="GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5"></a> <span id="PAGE" style="display:none;">13/33</span> <!-- End Header -->
<a id="GADBD450"></a><a id="GADBD449"></a>
<h1 id="GADBD-GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" class="sect1"><span class="enumeration_chapter">10</span> Using the Kafka Handler</h1>
<div>
<p>Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.</p>
<p><span class="bold">Topics:</span></p>
</div>
<div>
<ul class="ullinks">
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-FAD2E590-361E-46CC-B7F4-3BB97E19680E">Overview</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-E43DB743-4A2A-4C2F-97E8-50BB22CACCE3">Detailed Functionality</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-D6DE6F83-049C-4E97-8535-736F22741D51">Schema Propagation</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-F3170919-9C2F-4C3A-8D51-CA5500C3B7FF">Performance Considerations</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-C9C0652E-7B39-4C9A-8360-09121B8B47CD">About Security</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-B3E28C32-9F7A-469E-9495-AC6D51CD6446">Metadata Change Events</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-042F88D1-24B9-4703-82B4-223433293650">Snappy Considerations</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a><br /></li>
</ul>
</div>
<div class="props_rev_3"><a id="GUID-FAD2E590-361E-46CC-B7F4-3BB97E19680E"></a>
<h2 id="GADBD-GUID-FAD2E590-361E-46CC-B7F4-3BB97E19680E" class="sect2"><span class="enumeration_section">10.1</span> Overview</h2>
<div>
<div class="section">
<p>The Oracle GoldenGate for Big Data Kafka Handler streams change capture data from an Oracle GoldenGate trail to a Kafka topic. Additionally, the Kafka Handler provides functionality to publish messages to a separate schema topic. Schema publication for Avro and JSON is supported.</p>
<p>Apache Kafka is an open source, distributed, partitioned, and replicated messaging service, see <a href="http://kafka.apache.org/" target="_blank">http://kafka.apache.org/</a>.</p>
<p>Kafka can be run as a single instance or as a cluster on multiple servers. Each Kafka server instance is called a broker. A Kafka topic is a category or feed name to which messages are published by the producers and retrieved by consumers.</p>
<p>In Kafka, when the topic name corresponds to the fully-qualified source table name, the Kafka Handler implements a Kafka producer. The Kafka producer writes serialized change data capture, from multiple source tables to either a single configured topic or separating source operations, to different Kafka topics.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD460"></a>
<div class="props_rev_3"><a id="GUID-E43DB743-4A2A-4C2F-97E8-50BB22CACCE3"></a>
<h2 id="GADBD-GUID-E43DB743-4A2A-4C2F-97E8-50BB22CACCE3" class="sect2"><span class="enumeration_section">10.2</span> Detailed Functionality</h2>
<div>
<div class="section">
<p class="subhead2">Transaction Versus Operation Mode</p>
<p>The Kafka Handler sends instances of the Kafka <code class="codeph">ProducerRecord</code> class to the Kafka producer API, which in turn publishes the <code class="codeph">ProducerRecord</code> to a Kafka topic. The Kafka <code class="codeph">ProducerRecord</code> effectively is the implementation of a Kafka message. The <code class="codeph">ProducerRecord</code> has two components: a key and a value. Both the key and value are represented as byte arrays by the Kafka Handler. This section describes how the Kafka Handler publishes data.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Transaction Mode</p>
<p>The following configuration sets the Kafka Handler to transaction mode:</p>
<p><code class="codeph">gg.handler.name.Mode=tx</code></p>
<p>In transaction mode, the serialized data is concatenated for every operation in a transaction from the source <span>Oracle GoldenGate</span> trail files. The contents of the concatenated operation data is the value of the Kafka <code class="codeph">ProducerRecord</code> object. The key of the Kafka <code class="codeph">ProducerRecord</code> object is NULL. The result is that Kafka messages comprise data from 1 to <span class="italic">N</span> operations, where <span class="italic">N</span> is the number of operations in the transaction.</p>
<p>For grouped transactions, all the data for all the operations are concatenated into a single Kafka message. Therefore, grouped transactions may result in very large Kafka messages that contain data for a large number of operations.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Operation Mode</p>
<p>The following configuration sets the Kafka Handler to operation mode:</p>
<p><code class="codeph">gg.handler.name.Mode=op</code></p>
<p>In operation mode, the serialized data for each operation is placed into an individual <code class="codeph">ProducerRecord</code> object as the value. The <code class="codeph">ProducerRecord</code> key is the fully qualified table name of the source operation. The <code class="codeph">ProducerRecord</code> is immediately sent using the Kafka Producer API. This means that there is a 1 to 1 relationship between the incoming operations and the number of Kafka messages produced.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Blocking Versus Non-Blocking Mode</p>
</div>
<!-- class="section" -->
<p>The Kafka Handler can send messages to Kafka in either blocking mode (synchronous) or non-blocking mode (asynchronous).</p>
<div class="section">
<p class="subhead2">Blocking Mode</p>
<p>The following configuration property sets the Kafka Handler to blocking mode:</p>
<p><code class="codeph">gg.handler.name.BlockingSend=true</code></p>
<p>Messages are delivered to Kafka on a synchronous basis. The Kafka Handler does not send the next message until the current message has been written to the intended topic and an acknowledgement has been received. Blocking mode provides the best guarantee of message delivery but at the cost of reduced performance.</p>
<p>You must <span class="italic">never</span> set the Kafka Producer <code class="codeph">linger.ms</code> variable when in blocking mode, as this causes the Kafka producer to wait for the entire timeout period before sending the message to the Kafka broker. When this happens, the Kafka Handler waits for acknowledgement that the message has been sent while at the same time the Kafka Producer buffers messages to be sent to the Kafka brokers.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Non-Blocking Mode</p>
<p>The following configuration property sets the Kafka Handler to non-blocking mode:</p>
<p><code class="codeph">gg.handler.name.BlockingSend=false</code></p>
<p>Messages are delivered to Kafka asynchronously. Kafka messages are published one after the other without waiting for acknowledgements. The Kafka Producer client may buffer incoming messages in order to increase throughput.</p>
<p>On each transaction commit, the Kafka producer flush call is invoked to ensure that all outstanding messages are transferred to the Kafka cluster. This allows the Kafka Handler to safely checkpoint, ensuring zero data loss. Invocation of the Kafka producer flush call is not affected by the <code class="codeph">linger.ms</code> duration. This allows the Kafka Handler to safely checkpoint ensuring zero data loss.</p>
<p>You can control when the Kafka Producer flushes data to the Kafka Broker by a number of configurable properties in the Kafka producer configuration file. In order to enable batch sending of messages by the Kafka Producer, both the <code class="codeph">batch.size</code> and <code class="codeph">linger.ms</code> Kafka Producer properties must be set. The <code class="codeph">batch.size</code> controls the maximum number of bytes to buffer before a send to Kafka, while the <code class="codeph">linger.ms</code> variable controls the maximum milliseconds to wait before sending data. Data is sent to Kafka once the <code class="codeph">batch.size</code> is reached or when the <code class="codeph">linger.ms</code> period expires, whichever comes first. Setting the <code class="codeph">batch.size</code> variable only ensures that messages are sent immediately to Kafka.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Topic Name Selection</p>
<p>The topic is resolved at runtime using this configuration parameter:</p>
<pre dir="ltr">
gg.handler.topicMappingTemplate 
</pre>
<p>You can configure a static string, keywords, or a combination of static strings and keywords to dynamically resolve the topic name at runtime based on the context of the current operation, see <a href="using-kafka-connect-handler.htm#GUID-A87CAFFA-DACF-43A0-8C6C-5C64B578D606">Using Templates to Resolve the Topic Name and Message Key</a>.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Kafka Broker Settings</p>
<p>To configure topics to be created automatically, set the <code class="codeph">auto.create.topics.enable</code> property to <code class="codeph">true</code>. This is the default setting.</p>
<p>If you set the <code class="codeph">auto.create.topics.enable</code> property to <code class="codeph">false</code>, then you must manually create topics before you start the Replicat process.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead2">Schema Propagation</p>
<p>The schema data for all tables is delivered to the schema topic that is configured with the <code class="codeph">schemaTopicName</code> property. For more information , see <a href="using-kafka-handler.htm#GUID-D6DE6F83-049C-4E97-8535-736F22741D51">Schema Propagation</a>.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD451"></a>
<div class="props_rev_3"><a id="GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC"></a>
<h2 id="GADBD-GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC" class="sect2"><span class="enumeration_section">10.3</span> Setting Up and Running the Kafka Handler</h2>
<div>
<p>Instructions for configuring the Kafka Handler components and running the handler are described in this section.</p>
<p>You must install and correctly configure Kafka either as a single node or a clustered instance, see <a href="http://kafka.apache.org/documentation.html" target="_blank">http://kafka.apache.org/documentation.html</a>.</p>
<p>If you are using a Kafka distribution other than Apache Kafka, then consult the documentation for your Kafka distribution for installation and configuration instructions.</p>
<p>Zookeeper, a prerequisite component for Kafka and Kafka broker (or brokers), must be up and running.</p>
<p>Oracle recommends and considers it best practice that the data topic and the schema topic (if applicable) are preconfigured on the running Kafka brokers. You can create Kafka topics dynamically. However, this relies on the Kafka brokers being configured to allow dynamic topics.</p>
<p>If the Kafka broker is not collocated with the Kafka Handler process, then the remote host port must be reachable from the machine running the Kafka Handler.</p>
<p><span class="bold">Topics:</span></p>
</div>
<div>
<ul class="ullinks">
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-AEEC309C-4B0B-44C3-A3A5-0B86635CF93D">Classpath Configuration</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-B0B28444-7A93-4DC9-BD46-2F1C7D8058FE">Kafka Handler Configuration</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-81E572E9-C5BE-4D5D-943C-8543AC749EEC">Java Adapter Properties File</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-A5591368-FC03-4BD6-8A09-53DD9D25BDB9">Kafka Producer Configuration File</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-2D4D4244-B67B-4790-AF83-6A11D0A33AEE">Using Templates to Resolve the Topic Name and Message Key</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-4E4C6D20-4D76-4F58-94DC-32B0E7078DC8">Kafka Configuring with Kerberos on a Hadoop Platform</a><br /></li>
</ul>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
<a id="GADBD453"></a>
<div class="props_rev_3"><a id="GUID-AEEC309C-4B0B-44C3-A3A5-0B86635CF93D"></a>
<h3 id="GADBD-GUID-AEEC309C-4B0B-44C3-A3A5-0B86635CF93D" class="sect3"><span class="enumeration_section">10.3.1</span> Classpath Configuration</h3>
<div>
<div class="section">
<p>For the Kafka Handler to connect to Kafka and run, the Kafka Producer properties file and the Kafka client JARs must be configured in the <code class="codeph">gg.classpath</code> configuration variable. The Kafka client JARs must match the version of Kafka that the Kafka Handler is connecting to. For a list of the required client JAR files by version, see <a href="kafka-handler-client-dependencies.htm#GUID-1C21BC19-B3E9-462C-809C-9440CAB3A427" title="What are the dependencies for the Kafka Handler to connect to Apache Kafka databases?">Kafka Handler Client Dependencies</a>.</p>
<p>The recommended storage location for the Kafka Producer properties file is the Oracle GoldenGate <code class="codeph">dirprm</code> directory.</p>
<p>The default location of the Kafka client JARs is <span class="italic"><code class="codeph">Kafka_Home</code></span><code class="codeph">/libs/*.</code></p>
<p>The <code class="codeph">gg.classpath</code> must be configured precisely. The path of the Kafka Producer Properties file must contain the path with no wildcard appended. If the <code class="codeph">*</code> wildcard is included in the path to the Kafka Producer Properties file, the file is not picked up. Conversely, path to the dependency JARs must include the <code class="codeph">*</code> wild card character in order to include all the JAR files in that directory in the associated classpath. Do <span class="italic">not</span> use <code class="codeph">*.jar.</code> The following is an example of the correctly configured classpath:</p>
<p><code class="codeph">gg.classpath={kafka install dir}/libs/*</code></p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD456"></a><a id="GADBD455"></a>
<div class="props_rev_3"><a id="GUID-B0B28444-7A93-4DC9-BD46-2F1C7D8058FE"></a>
<h3 id="GADBD-GUID-B0B28444-7A93-4DC9-BD46-2F1C7D8058FE" class="sect3"><span class="enumeration_section">10.3.2</span> Kafka Handler Configuration</h3>
<div>
<div class="section">
<p>The following are the configurable values for the Kafka Handler. These properties are located in the Java Adapter properties file (not in the Replicat properties file).</p>
<p>To enable the selection of the Kafka Handler, you must first configure the handler type by specifying <code class="codeph">gg.handler.jdbc.type=kafka</code> and the other Kafka properties as follows:</p>
<div class="tblformalwide" id="GUID-B0B28444-7A93-4DC9-BD46-2F1C7D8058FE__GUID-E0BE3B27-B743-4317-845E-F4636AE9027A">
<p class="titleintable">Table 10-1 Configuration Properties for Kafka Handler</p>
<table class="cellalignment87" title="Configuration Properties for Kafka Handler" summary="Five column tabled describing the configuration properties for Kafka Handler">
<thead>
<tr class="cellalignment65">
<th class="cellalignment88" id="d49424e505">Property Name</th>
<th class="cellalignment89" id="d49424e508">Required / Optional</th>
<th class="cellalignment90" id="d49424e511">Property Value</th>
<th class="cellalignment90" id="d49424e514">Default</th>
<th class="cellalignment91" id="d49424e517">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e522" headers="d49424e505">
<p><code class="codeph">gg.handlerlist</code></p>
</td>
<td class="cellalignment93" headers="d49424e522 d49424e508">
<p>Required</p>
</td>
<td class="cellalignment94" headers="d49424e522 d49424e511">
<p><span class="italic"><code class="codeph">name</code></span> (choice of any name)</p>
</td>
<td class="cellalignment94" headers="d49424e522 d49424e514">
<p>None</p>
</td>
<td class="cellalignment95" headers="d49424e522 d49424e517">
<p>List of handlers to be used.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e542" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.type</code></p>
</td>
<td class="cellalignment93" headers="d49424e542 d49424e508">
<p>Required</p>
</td>
<td class="cellalignment94" headers="d49424e542 d49424e511">
<p><code class="codeph">kafka</code></p>
</td>
<td class="cellalignment94" headers="d49424e542 d49424e514">
<p>None</p>
</td>
<td class="cellalignment95" headers="d49424e542 d49424e517">
<p>Type of handler to use.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e563" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.KafkaProducerConfigFile</code></p>
</td>
<td class="cellalignment93" headers="d49424e563 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e563 d49424e511">
<p>Any custom file name</p>
</td>
<td class="cellalignment94" headers="d49424e563 d49424e514">
<p><code class="codeph">kafka-producer-default.properties</code></p>
</td>
<td class="cellalignment95" headers="d49424e563 d49424e517">
<p>Filename in classpath that holds Apache Kafka properties to configure the Apache Kafka producer.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e584" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.Format</code></p>
</td>
<td class="cellalignment93" headers="d49424e584 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e584 d49424e511">
<p>Formatter class or short code.</p>
</td>
<td class="cellalignment94" headers="d49424e584 d49424e514">
<p><code class="codeph">delimitedtext</code></p>
</td>
<td class="cellalignment95" headers="d49424e584 d49424e517">
<p>Formatter to use to format payload. Can be one of <code class="codeph">xml</code>, <code class="codeph">delimitedtext</code>, <code class="codeph">json</code>, <code class="codeph">json_row</code>, <code class="codeph">avro_row</code>, <code class="codeph">avro_op</code></p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e623" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.SchemaTopicName</code></p>
</td>
<td class="cellalignment93" headers="d49424e623 d49424e508">
<p>Required when schema delivery is required.</p>
</td>
<td class="cellalignment94" headers="d49424e623 d49424e511">
<p>Name of the schema topic.</p>
</td>
<td class="cellalignment94" headers="d49424e623 d49424e514">
<p>None</p>
</td>
<td class="cellalignment95" headers="d49424e623 d49424e517">
<p>Topic name where schema data will be delivered. If this property is not set, schema will not be propagated. Schemas will be propagated only for Avro formatters.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e643" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.SchemaPrClassName</code></p>
</td>
<td class="cellalignment93" headers="d49424e643 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e643 d49424e511">
<p>Fully qualified class name of a custom class that implements Oracle GoldenGate for Big Data Kafka Handler's <code class="codeph">CreateProducerRecord</code> Java Interface.</p>
</td>
<td class="cellalignment94" headers="d49424e643 d49424e514">
<p>Provided this implementation class: <code class="codeph">oracle.goldengate.handler.kafka</code></p>
<p><code class="codeph">ProducerRecord</code></p>
</td>
<td class="cellalignment95" headers="d49424e643 d49424e517">
<p>Schema is also propagated as a <code class="codeph">ProducerRecord</code>. The default key is the fully qualified table name. If this needs to be changed for schema records, the custom implementation of the <code class="codeph">CreateProducerRecord</code> interface needs to be created and this property needs to be set to point to the fully qualified name of the new class.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e677" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.BlockingSend</code></p>
</td>
<td class="cellalignment93" headers="d49424e677 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e677 d49424e511">
<p><code class="codeph">true</code> | <code class="codeph">false</code></p>
</td>
<td class="cellalignment94" headers="d49424e677 d49424e514">
<p><code class="codeph">false</code></p>
</td>
<td class="cellalignment95" headers="d49424e677 d49424e517">
<p>If this property is set to true, then delivery to Kafka works in a completely synchronous model. The next payload is sent only after the current payload has been written to the intended topic and an acknowledgement has been received. In transaction mode, this provides exactly once semantics. If this property is set to false, then delivery to Kafka is made to work in an asynchronous model. Payloads are sent one after the other without waiting for acknowledgements. Kafka internal queues may buffer contents to increase throughput. Checkpoints are made only when acknowledgements are received from Kafka brokers using Java callbacks.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e702" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.mode</code></p>
</td>
<td class="cellalignment93" headers="d49424e702 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e702 d49424e511">
<p><code class="codeph">tx</code>/<code class="codeph">op</code></p>
</td>
<td class="cellalignment94" headers="d49424e702 d49424e514">
<p><code class="codeph">tx</code></p>
</td>
<td class="cellalignment95" headers="d49424e702 d49424e517">
<p>With Kafka Handler operation mode, each change capture data record (Insert, Update, Delete, and so on) payload is represented as a Kafka Producer Record and is flushed one at a time. With Kafka Handler in transaction mode, all operations within a source transaction are represented as a single Kafka Producer record. This combined byte payload is flushed on a transaction Commit event.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e727" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.topicMappingTemplate</code></p>
</td>
<td class="cellalignment93" headers="d49424e727 d49424e508">
<p>Required</p>
</td>
<td class="cellalignment94" headers="d49424e727 d49424e511">
<p>A template string value to resolve the Kafka topic name at runtime.</p>
</td>
<td class="cellalignment94" headers="d49424e727 d49424e514">
<p>None</p>
</td>
<td class="cellalignment95" headers="d49424e727 d49424e517">
<p>See <a href="using-kafka-connect-handler.htm#GUID-A87CAFFA-DACF-43A0-8C6C-5C64B578D606">Using Templates to Resolve the Topic Name and Message Key</a>.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e750" headers="d49424e505">
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.keyMappingTemplate</code></p>
</td>
<td class="cellalignment93" headers="d49424e750 d49424e508">
<p>Required</p>
</td>
<td class="cellalignment94" headers="d49424e750 d49424e511">
<p>A template string value to resolve the Kafka message key at runtime.</p>
</td>
<td class="cellalignment94" headers="d49424e750 d49424e514">
<p>None</p>
</td>
<td class="cellalignment95" headers="d49424e750 d49424e517">
<p>See <a href="using-kafka-connect-handler.htm#GUID-A87CAFFA-DACF-43A0-8C6C-5C64B578D606">Using Templates to Resolve the Topic Name and Message Key</a>.</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment92" id="d49424e773" headers="d49424e505">
<p><code class="codeph">gg.hander.name.logSuccessfullySentMessages</code></p>
</td>
<td class="cellalignment93" headers="d49424e773 d49424e508">
<p>Optional</p>
</td>
<td class="cellalignment94" headers="d49424e773 d49424e511">
<p><code class="codeph">true</code> | <code class="codeph">false</code></p>
</td>
<td class="cellalignment94" headers="d49424e773 d49424e514">
<p><code class="codeph">true</code></p>
</td>
<td class="cellalignment95" headers="d49424e773 d49424e517">
<p>Set to <code class="codeph">true</code>, the Kafka Handler will log at the <code class="codeph">INFO</code> level message that have been successfully sent to Kafka. Enabling this property has negative impact onnnperformance.</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD458"></a>
<div class="props_rev_3"><a id="GUID-81E572E9-C5BE-4D5D-943C-8543AC749EEC"></a>
<h3 id="GADBD-GUID-81E572E9-C5BE-4D5D-943C-8543AC749EEC" class="sect3"><span class="enumeration_section">10.3.3</span> Java Adapter Properties File</h3>
<div>
<p>The following is a sample configuration for the Kafka Handler from the Adapter properties file:</p>
<pre dir="ltr">
gg.handlerlist = kafkahandler
gg.handler.kafkahandler.Type = kafka
gg.handler.kafkahandler.KafkaProducerConfigFile = custom_kafka_producer.properties
gg.handler.kafkahandler.topicMappingTemplate=oggtopic
gg.handler.kafkahandler.keyMappingTemplate=${currentTimestamp}
gg.handler.kafkahandler.Format = avro_op
gg.handler.kafkahandler.SchemaTopicName = oggSchemaTopic
gg.handler.kafkahandler.SchemaPrClassName = com.company.kafkaProdRec.SchemaRecord
gg.handler.kafkahandler.Mode = tx
gg.handler.kafkahandler.BlockingSend = true
</pre>
<p>You can find a sample Replicat configuration and a Java Adapter Properties file for a Kafka integration in the following directory:</p>
<p><span class="italic"><code class="codeph">GoldenGate_install_directory</code></span><code class="codeph">/AdapterExamples/big-data/kafka</code></p>
</div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD459"></a>
<div class="props_rev_3"><a id="GUID-A5591368-FC03-4BD6-8A09-53DD9D25BDB9"></a>
<h3 id="GADBD-GUID-A5591368-FC03-4BD6-8A09-53DD9D25BDB9" class="sect3"><span class="enumeration_section">10.3.4</span> Kafka Producer Configuration File</h3>
<div>
<div class="section">
<p>The Kafka Handler must access a Kafka producer configuration file in order to publish messages to Kafka. The file name of the Kafka producer configuration file is controlled by the following configuration in the Kafka Handler properties.</p>
<pre dir="ltr">
gg.handler.kafkahandler.KafkaProducerConfigFile=<span class="italic">custom_kafka_producer</span>.properties
</pre>
<p>The Kafka Handler attempts to locate and load the Kafka producer configuration file by using the Java classpath. Therefore, the Java classpath must include the directory containing the Kafka Producer Configuration File.</p>
<p>The Kafka producer configuration file contains Kafka proprietary properties. The Kafka documentation provides configuration information for the 0.8.2.0 Kafka producer interface properties. The Kafka Handler uses these properties to resolve the host and port of the Kafka brokers, and properties in the Kafka producer configuration file control the behavior of the interaction between the Kafka producer client and the Kafka brokers.</p>
<p>A sample of configuration file for the Kafka producer is as follows:</p>
<pre dir="ltr">
bootstrap.servers=localhost:9092
acks = 1
compression.type = gzip
reconnect.backoff.ms = 1000
 
value.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
key.serializer = org.apache.kafka.common.serialization.ByteArraySerializer
# 100KB per partition
batch.size = 102400
linger.ms = 0
max.request.size = 1048576 
send.buffer.bytes = 131072
</pre></div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<div class="props_rev_3"><a id="GUID-2D4D4244-B67B-4790-AF83-6A11D0A33AEE"></a>
<h3 id="GADBD-GUID-2D4D4244-B67B-4790-AF83-6A11D0A33AEE" class="sect3"><span class="enumeration_section">10.3.5</span> Using Templates to Resolve the Topic Name and Message Key</h3>
<div>
<div class="section">
<p>The Kafka Handler provides functionality to resolve the topic name and the message key at runtime using a template configuration value. Templates allow you to configure static values and keywords. Keywords are used to dynamically replace the keyword with the context of the current processing. The templates use the following configuration properties:</p>
<pre dir="ltr">
gg.handler.<span class="italic">name</span>.topicMappingTemplate
gg.handler.<span class="italic">name</span>.keyMappingTemplate
</pre></div>
<!-- class="section" -->
<div class="section">
<p class="subhead3">Template Modes</p>
<p>Source database transactions are made up of one or more individual operations that are the individual inserts, updates, and deletes. The Kafka Handler can be configured to send one message per operation (insert, update, delete), or alternatively can be configured to group operations into messages at the transaction level. Many template keywords resolve data based on the context of an individual source database operation. Therefore, many of the keywords do <span class="italic">not</span> work when sending messages at the transaction level. For example, using <code class="codeph">${<span class="codeinlineitalic">fullyQualifiedTableName</span>}</code> does not work when sending messages at the transaction level rather it resolves to the qualified source table name for an operation. However, transactions can contain multiple operations for many source tables. Resolving the fully qualified table name for messages at the transaction level is non-deterministic so abends at runtime.</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead3">Template Keywords</p>
<p>This table includes a column if the keyword is supported for transaction level messages.</p>
<div class="tblformal" id="GUID-2D4D4244-B67B-4790-AF83-6A11D0A33AEE__GUID-D9A8DB8F-BB51-4D27-9343-035157B21077">
<table class="cellalignment78" summary="Three column table describing Kafka Handler template keywords.">
<thead>
<tr class="cellalignment65">
<th class="cellalignment77" id="d49424e942">Keyword</th>
<th class="cellalignment77" id="d49424e945">Explanation</th>
<th class="cellalignment77" id="d49424e948">Transaction Message Support</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e953" headers="d49424e942">
<p><code class="codeph">${<span class="codeinlineitalic">fullyQualifiedTableName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e953 d49424e945">
<p>Resolves to the fully qualified table name including the period (.) delimiter between the catalog, schema, and table names.</p>
<p>For example, <code class="codeph">test.dbo.table1</code>.</p>
</td>
<td class="cellalignment65" headers="d49424e953 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e972" headers="d49424e942">
<p><code class="codeph">${<span class="codeinlineitalic">catalogName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e972 d49424e945">
<p>Resolves to the catalog name.</p>
</td>
<td class="cellalignment65" headers="d49424e972 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e986" headers="d49424e942">
<p><code class="codeph">${<span class="codeinlineitalic">schemaName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e986 d49424e945">
<p>Resolves to the schema name.</p>
</td>
<td class="cellalignment65" headers="d49424e986 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1000" headers="d49424e942">
<p><code class="codeph">${<span class="codeinlineitalic">tableName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1000 d49424e945">
<p>Resolves to the short table name.</p>
</td>
<td class="cellalignment65" headers="d49424e1000 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1014" headers="d49424e942">
<p><code class="codeph">${opType}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1014 d49424e945">
<p>Resolves to the type of the operation: (<code class="codeph">INSERT</code>, <code class="codeph">UPDATE</code>, <code class="codeph">DELETE</code>, or <code class="codeph">TRUNCATE</code>)</p>
</td>
<td class="cellalignment65" headers="d49424e1014 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1037" headers="d49424e942">
<p><code class="codeph">${primaryKeys}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1037 d49424e945">
<p>Resolves to the concatenated primary key values delimited by an underscore (_) character.</p>
</td>
<td class="cellalignment65" headers="d49424e1037 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1048" headers="d49424e942">
<p><code class="codeph">${position}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1048 d49424e945">
<p>The sequence number of the source trail file followed by the offset (RBA).</p>
</td>
<td class="cellalignment65" headers="d49424e1048 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1059" headers="d49424e942">
<p><code class="codeph">${opTimestamp}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1059 d49424e945">
<p>The operation timestamp from the source trail file.</p>
</td>
<td class="cellalignment65" headers="d49424e1059 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1070" headers="d49424e942">
<p><code class="codeph">${emptyString}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1070 d49424e945">
<p>Resolves to &ldquo;&rdquo;.</p>
</td>
<td class="cellalignment65" headers="d49424e1070 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1081" headers="d49424e942">
<p><code class="codeph">${<span class="codeinlineitalic">groupName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1081 d49424e945">
<p>Resolves to the name of the Replicat process. If using coordinated delivery, it resolves to the name of the Replicat process with the Replicate thread number appended.</p>
</td>
<td class="cellalignment65" headers="d49424e1081 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1095" headers="d49424e942">
<p><code class="codeph">${staticMap[]}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1095 d49424e945">
<p>Resolves to a static value where the key is the fully-qualified table name. The keys and values are designated inside of the square brace in the following format:</p>
<pre dir="ltr">
${staticMap[dbo.table1=value1,dbo.table2=value2]}
</pre></td>
<td class="cellalignment65" headers="d49424e1095 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1109" headers="d49424e942">
<p><code class="codeph">${columnValue[]}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1109 d49424e945">
<p>Resolves to a column value where the key is the fully-qualified table name and the value is the column name to be resolved. For example:</p>
<pre dir="ltr">
${staticMap[dbo.table1=col1,dbo.table2=col2]}
</pre></td>
<td class="cellalignment65" headers="d49424e1109 d49424e948">
<p>No</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1122" headers="d49424e942">
<p><code class="codeph">${currentTimestamp}</code></p>
<p>Or</p>
<p><code class="codeph">${currentTimestamp[]}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1122 d49424e945">
<p>Resolves to the current timestamp. You can control the format of the current timestamp using the Java based formatting as described in the <code class="codeph">SimpleDateFormat</code> class, see <a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html" target="_blank">https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html</a>.</p>
<p>Examples:</p>
<pre dir="ltr">
${currentDate}
${currentDate[yyyy-mm-dd hh:MM:ss.SSS]}
</pre></td>
<td class="cellalignment65" headers="d49424e1122 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1149" headers="d49424e942">
<p><code class="codeph">${null}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1149 d49424e945">
<p>Resolves to a NULL string.</p>
</td>
<td class="cellalignment65" headers="d49424e1149 d49424e948">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1160" headers="d49424e942">
<p><code class="codeph">${custom[]}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1160 d49424e945">
<p>It is possible to write a custom value resolver. If required, contact Oracle Support.</p>
</td>
<td class="cellalignment65" headers="d49424e1160 d49424e948">
<p>Implementation dependent</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
<!-- class="section" -->
<div class="section">
<p class="subhead3">Example Templates</p>
<p>The following describes example template configuration values and the resolved values.</p>
<div class="tblformal" id="GUID-2D4D4244-B67B-4790-AF83-6A11D0A33AEE__GUID-5F1F62DC-D9B8-4609-B8B4-046CD8140201">
<table class="cellalignment78" summary="A two column table describing example Kafka Handler example templates.">
<thead>
<tr class="cellalignment65">
<th class="cellalignment77" id="d49424e1183">Example Template</th>
<th class="cellalignment77" id="d49424e1186">Resolved Value</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1191" headers="d49424e1183">
<p><code class="codeph">${groupName}_{<span class="codeinlineitalic">fullyQualfiedTableName</span>}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1191 d49424e1186">
<p><code class="codeph">KAFKA001_dbo.table1</code></p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1203" headers="d49424e1183">
<p><code class="codeph">prefix_${<span class="codeinlineitalic">schemaName</span>}_${<span class="codeinlineitalic">tableName</span>}_suffix</code></p>
</td>
<td class="cellalignment65" headers="d49424e1203 d49424e1186">
<p><code class="codeph">prefix_dbo_table1_suffix</code></p>
</td>
</tr>
<tr class="cellalignment65">
<td class="cellalignment65" id="d49424e1218" headers="d49424e1183">
<p><code class="codeph">${currentDate[yyyy-mm-dd hh:MM:ss.SSS]}</code></p>
</td>
<td class="cellalignment65" headers="d49424e1218 d49424e1186">
<p><code class="codeph">2017-05-17 11:45:34.254</code></p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<div class="props_rev_3"><a id="GUID-4E4C6D20-4D76-4F58-94DC-32B0E7078DC8"></a>
<h3 id="GADBD-GUID-4E4C6D20-4D76-4F58-94DC-32B0E7078DC8" class="sect3"><span class="enumeration_section">10.3.6</span> Kafka Configuring with Kerberos on a Hadoop Platform</h3>
<div>
<div class="section">
<p>Use these steps to configure a Kafka Handler Replicat with Kerberos to enable a Cloudera instance to process an <span>Oracle GoldenGate for Big Data</span> trail to a Kafka topic:</p>
<ol>
<li>
<p>In GGSCI, add a Kafka Replicat:</p>
<pre dir="ltr">
GGSCI&gt; add replicat kafka, exttrail dirdat/gg
</pre></li>
<li>
<p>Configure a <code class="codeph">prm</code> file with these properties:</p>
<pre dir="ltr">
replicat kafka
discardfile ./dirrpt/kafkax.dsc, purge
SETENV (TZ=PST8PDT)
GETTRUNCATES
GETUPDATEBEFORES
ReportCount Every 1000 Records, Rate
MAP qasource.*, target qatarget.*;
</pre></li>
<li>
<p>Configure a Replicat properties file as follows:</p>
<pre dir="ltr">
###KAFKA Properties file ###
gg.log=log4j
gg.log.level=info
gg.report.time=30sec

###Kafka Classpath settings ###
gg.classpath=/opt/cloudera/parcels/KAFKA-2.1.0-1.2.1.0.p0.115/lib/kafka/libs/*
jvm.bootoptions=-Xmx64m -Xms64m -Djava.class.path=./ggjava/ggjava.jar -Dlog4j.configuration=log4j.properties -Djava.security.auth.login.config=/scratch/ydama/ogg/v123211/dirprm/jaas.conf -Djava.security.krb5.conf=/etc/krb5.conf

javawriter.stats.full=TRUE
javawriter.stats.display=TRUE

### native library config ###
goldengate.userexit.nochkpt=TRUE
goldengate.userexit.timestamp=utc

### Kafka handler properties ###
gg.handlerlist = kafkahandler
gg.handler.kafkahandler.type=kafka
gg.handler.kafkahandler.KafkaProducerConfigFile=kafka-producer.properties
gg.handler.kafkahandler.format=delimitedtext
gg.handler.kafkahandler.format.PkUpdateHandling=update
gg.handler.kafkahandler.mode=tx
gg.handler.kafkahandler.format.includeCurrentTimestamp=false
#gg.handler.kafkahandler.maxGroupSize=100
#gg.handler.kafkahandler.minGroupSize=50
gg.handler.kafkahandler.format.fieldDelimiter=|
gg.handler.kafkahandler.format.lineDelimiter=CDATA[\n]
gg.handler.kafkahandler.topicMappingTemplate=myoggtopic
gg.handler.kafkahandler.keyMappingTemplate=${position}
</pre></li>
<li>
<p>Configure a Kafka Producer file with these properties:</p>
<pre dir="ltr">
bootstrap.servers=10.245.172.52:9092
acks=1
#compression.type=snappy
reconnect.backoff.ms=1000
value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
batch.size=1024
linger.ms=2000

security.protocol=SASL_PLAINTEXT

sasl.kerberos.service.name=kafka
sasl.mechanism=GSSAPI
</pre></li>
<li>
<p>Configure a <code class="codeph">jaas.conf</code> file with these properties:</p>
<pre dir="ltr">
KafkaClient {
com.sun.security.auth.module.Krb5LoginModule required
useKeyTab=true
storeKey=true
keyTab="/scratch/ydama/ogg/v123211/dirtmp/keytabs/slc06unm/kafka.keytab"
principal="kafka/slc06unm.us.oracle.com@HADOOPTEST.ORACLE.COM";
};
</pre></li>
<li>
<p>Ensure that you have the latest <code class="codeph">key.tab</code> files from the Cloudera instance to connect secured Kafka topics.</p>
</li>
<li>
<p>Start the Replicat from GGSCI and make sure that it is running with <code class="codeph">INFO ALL</code>.</p>
</li>
<li>
<p>Review the Replicat report to see the total number of records processed. The report is similar to:</p>
<pre dir="ltr">
Oracle GoldenGate for Big Data, 12.3.2.1.1.005

Copyright (c) 2007, 2018. Oracle and/or its affiliates. All rights reserved

Built with Java 1.8.0_161 (class version: 52.0)

2018-08-05 22:15:28 INFO OGG-01815 Virtual Memory Facilities for: COM
anon alloc: mmap(MAP_ANON) anon free: munmap
file alloc: mmap(MAP_SHARED) file free: munmap
target directories:
/scratch/ydama/ogg/v123211/dirtmp.

Database Version:

Database Language and Character Set:

***********************************************************************
** Run Time Messages **
***********************************************************************


2018-08-05 22:15:28 INFO OGG-02243 Opened trail file /scratch/ydama/ogg/v123211/dirdat/kfkCustR/gg000000 at 2018-08-05 22:15:28.258810.

2018-08-05 22:15:28 INFO OGG-03506 The source database character set, as determined from the trail file, is UTF-8.

2018-08-05 22:15:28 INFO OGG-06506 Wildcard MAP resolved (entry qasource.*): MAP "QASOURCE"."BDCUSTMER1", target qatarget."BDCUSTMER1".

2018-08-05 22:15:28 INFO OGG-02756 The definition for table QASOURCE.BDCUSTMER1 is obtained from the trail file.

2018-08-05 22:15:28 INFO OGG-06511 Using following columns in default map by name: CUST_CODE, NAME, CITY, STATE.

2018-08-05 22:15:28 INFO OGG-06510 Using the following key columns for target table qatarget.BDCUSTMER1: CUST_CODE.

2018-08-05 22:15:29 INFO OGG-06506 Wildcard MAP resolved (entry qasource.*): MAP "QASOURCE"."BDCUSTORD1", target qatarget."BDCUSTORD1".

2018-08-05 22:15:29 INFO OGG-02756 The definition for table QASOURCE.BDCUSTORD1 is obtained from the trail file.

2018-08-05 22:15:29 INFO OGG-06511 Using following columns in default map by name: CUST_CODE, ORDER_DATE, PRODUCT_CODE, ORDER_ID, PRODUCT_PRICE, PRODUCT_AMOUNT, TRANSACTION_ID.

2018-08-05 22:15:29 INFO OGG-06510 Using the following key columns for target table qatarget.BDCUSTORD1: CUST_CODE, ORDER_DATE, PRODUCT_CODE, ORDER_ID.

2018-08-05 22:15:33 INFO OGG-01021 Command received from GGSCI: STATS.

2018-08-05 22:16:03 INFO OGG-01971 The previous message, 'INFO OGG-01021', repeated 1 times.

2018-08-05 22:43:27 INFO OGG-01021 Command received from GGSCI: STOP.

***********************************************************************
* ** Run Time Statistics ** *
***********************************************************************

Last record for the last committed transaction is the following:
___________________________________________________________________
Trail name : /scratch/ydama/ogg/v123211/dirdat/kfkCustR/gg000000
Hdr-Ind : E (x45) Partition : . (x0c)
UndoFlag : . (x00) BeforeAfter: A (x41)
RecLength : 0 (x0000) IO Time : 2015-08-14 12:02:20.022027
IOType : 100 (x64) OrigNode : 255 (xff)
TransInd : . (x03) FormatType : R (x52)
SyskeyLen : 0 (x00) Incomplete : . (x00)
AuditRBA : 78233 AuditPos : 23968384
Continued : N (x00) RecCount : 1 (x01)

2015-08-14 12:02:20.022027 GGSPurgedata Len 0 RBA 6473
TDR Index: 2
___________________________________________________________________

Reading /scratch/ydama/ogg/v123211/dirdat/kfkCustR/gg000000, current RBA 6556, 20 records, m_file_seqno = 0, m_file_rba = 6556

Report at 2018-08-05 22:43:27 (activity since 2018-08-05 22:15:28)

From Table QASOURCE.BDCUSTMER1 to qatarget.BDCUSTMER1:
# inserts: 5
# updates: 1
# deletes: 0
# discards: 0
From Table QASOURCE.BDCUSTORD1 to qatarget.BDCUSTORD1:
# inserts: 5
# updates: 3
# deletes: 5
# truncates: 1
# discards: 0

</pre></li>
<li>
<p>Ensure that the secure Kafka topic is created:</p>
<pre dir="ltr">
/kafka/bin/kafka-topics.sh --zookeeper slc06unm:2181 --list  
<span class="italic">myoggtopic</span>
</pre></li>
<li>
<p>Review the contents of the secure Kafka topic:</p>
<ol>
<li>
<p>Create a <code class="codeph">consumer.properties</code> file containing:</p>
<pre dir="ltr">
security.protocol=SASL_PLAINTEXT
sasl.kerberos.service.name=kafka
</pre></li>
<li>
<p>Set this environment variable:</p>
<pre dir="ltr">
export KAFKA_OPTS="-Djava.security.auth.login.config="/<span class="italic">scratch/ogg/v123211</span>/dirprm/jaas.conf"
</pre></li>
<li>
<p>Run the consumer utility to check the records:</p>
<pre dir="ltr">
/kafka/bin/kafka-console-consumer.sh --bootstrap-server <span class="italic">sys06</span>:<span class="italic">9092</span> --topic <span class="italic">myoggtopic</span> --new-consumer --consumer.config consumer.properties
</pre></li>
</ol>
</li>
</ol>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-1A0EC8A5-8710-47D6-BC46-C6946DC4F3EC">Setting Up and Running the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
</div>
<a id="GADBD467"></a>
<div class="props_rev_3"><a id="GUID-D6DE6F83-049C-4E97-8535-736F22741D51"></a>
<h2 id="GADBD-GUID-D6DE6F83-049C-4E97-8535-736F22741D51" class="sect2"><span class="enumeration_section">10.4</span> Schema Propagation</h2>
<div>
<p>The Kafka Handler provides the ability to publish schemas to a schema topic. Currently, the Avro Row and Operation formatters are the only formatters that are enabled for schema publishing. If the Kafka Handler <code class="codeph">schemaTopicName</code> property is set, then the schema is published for the following events:</p>
<ul style="list-style-type: disc;">
<li>
<p>The Avro schema for a specific table is published the first time an operation for that table is encountered.</p>
</li>
<li>
<p>If the Kafka Handler receives a metadata change event, the schema is flushed. The regenerated Avro schema for a specific table is published the next time an operation for that table is encountered.</p>
</li>
<li>
<p>If the Avro wrapping functionality is enabled, then the generic wrapper Avro schema is published the first time that any operation is encountered. To enable the generic wrapper, Avro schema functionality is enabled in the Avro formatter configuration, see <a href="using-pluggable-formatters.htm#GUID-3282CC22-92E8-4637-AD8D-E5E3F48BE9F5">Avro Row Formatter</a> and <a href="using-pluggable-formatters.htm#GUID-D77D819B-FDA2-4348-9899-711B50302F96">The Avro Operation Formatter</a>.</p>
</li>
</ul>
<p>The Kafka <code class="codeph">ProducerRecord</code> value is the schema, and the key is the fully qualified table name.</p>
<p>Because Avro messages directly depend on an Avro schema, user of Avro over Kafka may encounter issues. Avro messages are not human readable because they are binary. To deserialize an Avro message, the receiver must first have the correct Avro schema, but because each table from the source database results in a separate Avro schema, this can be difficult. The receiver of a Kafka message cannot determine which Avro schema to use to deserialize individual messages when the source Oracle GoldenGate trail file includes operations from multiple tables. To solve this problem, you can wrap the specialized Avro messages in a generic Avro message wrapper. This generic Avro wrapper provides the fully-qualified table name, the hashcode of the schema string, and the wrapped Avro message. The receiver can use the fully-qualified table name and the hashcode of the schema string to resolve the associated schema of the wrapped message, and then use that schema to deserialize the wrapped message.</p>
</div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD474"></a>
<div class="props_rev_3"><a id="GUID-F3170919-9C2F-4C3A-8D51-CA5500C3B7FF"></a>
<h2 id="GADBD-GUID-F3170919-9C2F-4C3A-8D51-CA5500C3B7FF" class="sect2"><span class="enumeration_section">10.5</span> Performance Considerations</h2>
<div>
<div class="section">
<p>Oracle recommends that you do <span class="italic">not</span> use the <code class="codeph">linger.ms</code> setting in the Kafka producer <code class="codeph">config</code> file when <code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.BlockingSend</code>.is set to <code class="codeph">true</code>. This causes each send to block for at least the value of <code class="codeph">linger.ms</code>, leading to major performance issues because the Kafka Handler configuration and the Kafka Producer configuration are in conflict with each other. This configuration results in a temporary deadlock scenario, where the Kafka Handler is waits to received a send acknowledgement while the Kafka producer waits for more messages before sending. The deadlock resolves when the <code class="codeph">linger.ms</code> period expires. This behavior repeats for every message sent.</p>
<p>For the best performance, Oracle recommends that you set the Kafka Handler to operate in operation mode using non-blocking (asynchronous) calls to the Kafka producer. Use the following configuration in your Java Adapter properties file:</p>
<pre dir="ltr">
gg.handler.<span class="italic">name</span>.mode = op
gg.handler.<span class="italic">name</span>.BlockingSend = false
</pre>
<p>Additionally, Oracle recommends that you set the <code class="codeph">batch.size</code> and linger.ms values in the Kafka Producer properties file. These values are highly dependent upon the use case scenario. Typically, higher values result in better throughput, but latency is increased. Smaller values in these properties reduces latency but overall throughput decreases. If you have a high volume of input data from the source trial files, then set the <code class="codeph">batch.size</code> and <code class="codeph">linger.ms</code> size as high as possible.</p>
<p>Use of the Replicat variable <code class="codeph">GROUPTRANSOPS</code> also improves performance. The recommended setting is <code class="codeph">10000</code>.</p>
<p>If the serialized operations from the source trail file must be delivered in individual Kafka messages, then the Kafka Handler must be set to operation mode.</p>
<p><code class="codeph">gg.handler.<span class="codeinlineitalic">name</span>.mode = op</code></p>
<p>However, the result is many more Kafka messages and adversely affected performance.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD475"></a>
<div class="props_rev_3"><a id="GUID-C9C0652E-7B39-4C9A-8360-09121B8B47CD"></a>
<h2 id="GADBD-GUID-C9C0652E-7B39-4C9A-8360-09121B8B47CD" class="sect2"><span class="enumeration_section">10.6</span> About Security</h2>
<div>
<p>Kafka version 0.9.0.0 introduced security through SSL/TLS and SASL (Kerberos). You can secure the Kafka Handler using one or both of the SSL/TLS and SASL security offerings. The Kafka producer client libraries provide an abstraction of security functionality from the integrations that use those libraries. The Kafka Handler is effectively abstracted from security functionality. Enabling security requires setting up security for the Kafka cluster, connecting machines, and then configuring the Kafka producer properties file with the required security properties. For detailed instructions about securing the Kafka cluster, see the Kafka documentation at</p>
<p>You may encounter the inability to decrypt the Kerberos password from the <code>keytab</code> file. This causes the Kerberos authentication to fall back to interactive mode which cannot work because it is being invoked programmatically. The cause of this problem is that the Java Cryptography Extension (JCE) is not installed in the Java Runtime Environment (JRE). Ensure that the JCE is loaded in the JRE, see <a href="http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html" target="_blank">http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html</a>.</p>
</div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD477"></a>
<div class="props_rev_3"><a id="GUID-B3E28C32-9F7A-469E-9495-AC6D51CD6446"></a>
<h2 id="GADBD-GUID-B3E28C32-9F7A-469E-9495-AC6D51CD6446" class="sect2"><span class="enumeration_section">10.7</span> Metadata Change Events</h2>
<div>
<div class="section">
<p>Metadata change events are now handled in the Kafka Handler. This is relevant only if you have configured a schema topic and the formatter used supports schema propagation (currently Avro row and Avro Operation formatters). The next time an operation is encountered for a table for which the schema has changed, the updated schema is published to the schema topic.</p>
<p>To support metadata change events, the Oracle GoldenGate process capturing changes in the source database must support the Oracle GoldenGate metadata in trail feature, which was introduced in Oracle GoldenGate 12<span class="italic">c</span> (12.2).</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD478"></a>
<div class="props_rev_3"><a id="GUID-042F88D1-24B9-4703-82B4-223433293650"></a>
<h2 id="GADBD-GUID-042F88D1-24B9-4703-82B4-223433293650" class="sect2"><span class="enumeration_section">10.8</span> Snappy Considerations</h2>
<div>
<div class="section">
<p>The Kafka Producer Configuration file supports the use of compression. One of the configurable options is Snappy, an open source compression and decompression (<code class="codeph">codec</code>) library that provides better performance than other <code class="codeph">codec</code> libraries. The Snappy JAR does not run on all platforms. Snappy may work on Linux systems though may or may not work on other UNIX and Windows implementations. If you want to use Snappy compression, test Snappy on all required systems before implementing compression using Snappy. If Snappy does not port to all required systems, then Oracle recommends using an alternate <code class="codeph">codec</code> library.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD468"></a>
<div class="props_rev_3"><a id="GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3"></a>
<h2 id="GADBD-GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3" class="sect2"><span class="enumeration_section">10.9</span> Troubleshooting</h2>
<div>
<p><span class="bold">Topics:</span></p>
</div>
<div>
<ul class="ullinks">
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-4792D2B4-5F2A-4108-8DD1-EE803AC2A663">Verify the Kafka Setup</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-A48DEA0E-BAE8-42CE-986D-59A8D46B7785">Classpath Issues</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-34E67463-A86E-42B2-AB8B-BDA115ACC5A0">Invalid Kafka Version</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-EF3E2568-00BE-457A-B7DC-C9A0E8E25715">Kafka Producer Properties File Not Found</a><br /></li>
<li class="ulchildlink"><a href="using-kafka-handler.htm#GUID-C9202B10-A376-49A1-92CD-32F35B6E7830">Kafka Connection Problem</a><br /></li>
</ul>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-2561CA12-9BAC-454B-A2E3-2D36C5C60EE5" title="Learn how to use the Kafka Handler, which is designed to stream change capture data from an Oracle GoldenGate trail to a Kafka topic.">Using the Kafka Handler</a></p>
</div>
</div>
</div>
<a id="GADBD469"></a>
<div class="props_rev_3"><a id="GUID-4792D2B4-5F2A-4108-8DD1-EE803AC2A663"></a>
<h3 id="GADBD-GUID-4792D2B4-5F2A-4108-8DD1-EE803AC2A663" class="sect3"><span class="enumeration_section">10.9.1</span> Verify the Kafka Setup</h3>
<div>
<div class="section">
<p>You can use the command line Kafka producer to write dummy data to a Kafka topic, and you can use a Kafka consumer to read this data from the Kafka topic. Use this method to verify the setup and read/write permissions to Kafka topics on disk, see <a href="http://kafka.apache.org/documentation.html#quickstart" target="_blank">http://kafka.apache.org/documentation.html#quickstart</a>.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD470"></a>
<div class="props_rev_3"><a id="GUID-A48DEA0E-BAE8-42CE-986D-59A8D46B7785"></a>
<h3 id="GADBD-GUID-A48DEA0E-BAE8-42CE-986D-59A8D46B7785" class="sect3"><span class="enumeration_section">10.9.2</span> Classpath Issues</h3>
<div>
<div class="section">
<p>Java classpath problems are common. Such problems may include a <code class="codeph">ClassNotFoundException</code> problem in the <code class="codeph">log4j</code> log file or may be an error resolving the classpath because of a typographic error in the <code class="codeph">gg.classpath</code> variable. The Kafka client libraries do <span class="italic">not</span> ship with the Oracle GoldenGate for Big Data product. You must obtain the correct version of the Kafka client libraries and properly configure the <code class="codeph">gg.classpath</code> property in the Java Adapter Properties file to correctly resolve the Java the Kafka client libraries as described in <a href="using-kafka-handler.htm#GUID-AEEC309C-4B0B-44C3-A3A5-0B86635CF93D">Classpath Configuration</a>.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD471"></a>
<div class="props_rev_3"><a id="GUID-34E67463-A86E-42B2-AB8B-BDA115ACC5A0"></a>
<h3 id="GADBD-GUID-34E67463-A86E-42B2-AB8B-BDA115ACC5A0" class="sect3"><span class="enumeration_section">10.9.3</span> Invalid Kafka Version</h3>
<div>
<div class="section">
<p>The Kafka Handler does <span class="italic">not</span> support Kafka versions 0.8.2.2 or older. If you run an unsupported version of Kafka, a runtime Java exception, <code class="codeph">java.lang.NoSuchMethodError</code>, occurs. It implies that the&nbsp; <code class="codeph">org.apache.kafka.clients.producer.KafkaProducer.flush()</code> method cannot be found. If you encounter this error, migrate to Kafka version 0.9.0.0 or later.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD472"></a>
<div class="props_rev_3"><a id="GUID-EF3E2568-00BE-457A-B7DC-C9A0E8E25715"></a>
<h3 id="GADBD-GUID-EF3E2568-00BE-457A-B7DC-C9A0E8E25715" class="sect3"><span class="enumeration_section">10.9.4</span> Kafka Producer Properties File Not Found</h3>
<div>
<div class="section">
<p>This problem typically results in the following exception:</p>
<pre dir="ltr">
ERROR 2015-11-11 11:49:08,482 [main] Error loading the kafka producer properties
</pre>
<p>Check the <code class="codeph">gg.handler.kafkahandler.KafkaProducerConfigFile</code> configuration variable to ensure that the Kafka Producer Configuration file name is set correctly. Check the <code class="codeph">gg.classpath</code> variable to verify that the classpath includes the path to the Kafka Producer properties file, and that the path to the properties file does not contain a <code class="codeph">*</code> wildcard at the end.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a></p>
</div>
</div>
</div>
</div>
<a id="GADBD473"></a>
<div class="props_rev_3"><a id="GUID-C9202B10-A376-49A1-92CD-32F35B6E7830"></a>
<h3 id="GADBD-GUID-C9202B10-A376-49A1-92CD-32F35B6E7830" class="sect3"><span class="enumeration_section">10.9.5</span> Kafka Connection Problem</h3>
<div>
<div class="section">
<p>This problem occurs when the Kafka Handler is unable to connect to Kafka. You receive the following warnings:</p>
<pre dir="ltr">
WARN 2015-11-11 11:25:50,784 [kafka-producer-network-thread | producer-1] WARN  (Selector.java:276) - Error in I/O with localhost/127.0.0.1 
java.net.ConnectException: Connection refused
</pre>
<p>The connection retry interval expires, and the Kafka Handler process abends. Ensure that the Kafka Broker is running and that the host and port provided in the Kafka Producer Properties file are correct. You can use network shell commands (such as <code class="codeph">netstat -l</code>) on the machine hosting the Kafka broker to verify that Kafka is listening on the expected port.</p>
</div>
<!-- class="section" --></div>
<div>
<div class="familylinks">
<div class="parentlink">
<p><strong>Parent topic:</strong> <a href="using-kafka-handler.htm#GUID-03E08F86-B05A-4504-9F10-AB9022ED8EE3">Troubleshooting</a></p>
</div>
</div>
</div>
</div>
</div>
</div>
<!-- class="ind" --><!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment64">
<tr>
<td class="cellalignment74">
<table class="cellalignment69">
<tr>
<td class="cellalignment68"><a href="using-jdbc-handler.htm"><img width="24" height="24" src="../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment68"><a href="using-kafka-connect-handler.htm"><img width="24" height="24" src="../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2015, 2018, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment76">
<table class="cellalignment67">
<tr>
<td class="cellalignment68"><a href="http://docs.oracle.com/goldengate/bd123210/gg-bd/index.html"><img width="24" height="24" src="../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment68"><a href="toc.htm"><img width="24" height="24" src="../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment68"><a href="../dcommon/html/feedback.htm"><img width="24" height="24" src="../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>
</body>
</html>
